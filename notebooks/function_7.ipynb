{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e4f5b7-026f-4545-91b7-7b40a0487d4e",
   "metadata": {},
   "source": [
    "## Function Description\n",
    "You’re tasked with optimising an ML model by tuning six hyperparameters, for example learning rate, regularisation strength or number of hidden layers. The function you’re maximising is the model’s performance score (such as accuracy or F1), but since the relationship between inputs and output isn’t known, it’s treated as a black-box function. The goal is to find the combination of hyperparameters that yields the highest possible performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c15c19d-2233-4f7b-bb85-e41bb5ed9d51",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944619bd-0398-45b2-9d47-92ffb698a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original n: 30\n",
      "\n",
      "X:\n",
      " [[0.272624 0.324495 0.897109 0.832951 0.154063 0.795864]\n",
      " [0.543003 0.924694 0.341567 0.646486 0.71844  0.343133]\n",
      " [0.090832 0.661529 0.065931 0.258577 0.963453 0.640265]\n",
      " [0.118867 0.615055 0.905816 0.8553   0.413631 0.585236]\n",
      " [0.630218 0.838097 0.680013 0.731895 0.526737 0.348429]\n",
      " [0.764919 0.255883 0.609084 0.218079 0.322943 0.095794]\n",
      " [0.057896 0.491672 0.247422 0.218118 0.420428 0.73097 ]\n",
      " [0.195252 0.079227 0.55458  0.170567 0.014944 0.107032]\n",
      " [0.642303 0.836875 0.021793 0.101488 0.683071 0.692416]\n",
      " [0.789943 0.195545 0.575623 0.073659 0.259049 0.0511  ]\n",
      " [0.528497 0.457424 0.360096 0.362046 0.816891 0.637476]\n",
      " [0.722615 0.011813 0.063646 0.165173 0.079244 0.359952]\n",
      " [0.075665 0.334502 0.132733 0.608312 0.918386 0.822331]\n",
      " [0.942451 0.37744  0.486122 0.228791 0.082632 0.711958]\n",
      " [0.148647 0.033943 0.728806 0.316066 0.021769 0.516918]\n",
      " [0.817112 0.548168 0.103348 0.12437  0.728235 0.449674]\n",
      " [0.417626 0.0641   0.245669 0.559041 0.191531 0.254641]\n",
      " [0.726286 0.464896 0.924571 0.807245 0.635438 0.143418]\n",
      " [0.31981  0.520098 0.290678 0.876707 0.495035 0.619082]\n",
      " [0.879871 0.397962 0.003635 0.956991 0.264514 0.114869]\n",
      " [0.541241 0.631403 0.031902 0.449982 0.798653 0.633704]\n",
      " [0.226348 0.115026 0.82475  0.945384 0.905312 0.951014]\n",
      " [0.686853 0.041017 0.007573 0.285009 0.691568 0.655543]\n",
      " [0.175978 0.624416 0.295542 0.469553 0.09777  0.728141]\n",
      " [0.881647 0.20445  0.414474 0.420385 0.264915 0.73066 ]\n",
      " [0.066611 0.528045 0.816095 0.961017 0.086509 0.777788]\n",
      " [0.932466 0.488812 0.258608 0.956243 0.190428 0.519852]\n",
      " [0.846867 0.142429 0.060669 0.756292 0.552398 0.081306]\n",
      " [0.806282 0.324122 0.726076 0.148712 0.719376 0.362884]\n",
      " [0.476823 0.340942 0.014335 0.88014  0.998655 0.079664]\n",
      " [0.273438 0.45069  0.413488 0.285023 0.37776  0.757027]\n",
      " [0.198552 0.498391 0.434876 0.254163 0.396552 0.721236]\n",
      " [0.01675  0.564445 0.498901 0.237872 0.376071 0.754913]\n",
      " [0.20282  0.35464  0.00557  0.266428 0.373516 0.013214]\n",
      " [0.236909 0.28553  0.225819 0.209358 0.366238 0.732886]\n",
      " [0.214572 0.419397 0.065811 0.152936 0.357296 0.694855]\n",
      " [0.29697  0.175224 0.967097 0.217682 0.381161 0.806737]\n",
      " [0.31193  0.244347 0.263703 0.233867 0.377674 0.741498]\n",
      " [0.346764 0.117855 0.122187 0.232967 0.342263 0.711485]\n",
      " [0.272196 0.506051 0.223097 0.23651  0.326314 0.797848]\n",
      " [0.274485 0.070371 0.163388 0.21331  0.371978 0.732172]\n",
      " [0.345007 0.158281 0.249855 0.159331 0.319883 0.69684 ]\n",
      " [0.321126 0.15964  0.384855 0.209467 0.349849 0.720931]]\n",
      "\n",
      "y:\n",
      " [0.604433 0.562753 0.007503 0.061424 0.273047 0.083747 1.364968 0.092645\n",
      " 0.01787  0.033565 0.073516 0.20631  0.008826 0.2684   0.611526 0.014798\n",
      " 0.274893 0.066763 0.042118 0.002701 0.018209 0.007016 0.100507 0.475396\n",
      " 0.675142 0.516457 0.003777 0.003134 0.021343 0.095411 1.883287 2.038741\n",
      " 1.4162   0.127496 2.328267 1.587311 1.315108 2.459608 2.463779 1.57828\n",
      " 2.356137 2.445684 2.811657]\n",
      "\n",
      "n:  43\n",
      "\n",
      "current maximum:\n",
      "n: 43\n",
      "y: 2.8116569452461184\n",
      "X: [0.321126 0.15964  0.384855 0.209467 0.349849 0.720931]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from scipy.stats.qmc import Sobol\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=ConvergenceWarning,\n",
    "    module=\"sklearn\"\n",
    ")\n",
    "\n",
    "# Load original dataset\n",
    "X = np.load(\"../data/function_7/initial_inputs.npy\")\n",
    "y = np.load(\"../data/function_7/initial_outputs.npy\")\n",
    "d = X.shape[1] # dimension\n",
    "\n",
    "print(f\"original n: {len(X)}\")\n",
    "print()\n",
    "\n",
    "# week 1 = initial\n",
    "\n",
    "# week 2\n",
    "x_new = np.array([[0.273438, 0.450690, 0.413488, 0.285023, 0.377760, 0.757027]])\n",
    "y_new = np.array([1.883287428633328])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 3\n",
    "x_new = np.array([[0.198552, 0.498391, 0.434876, 0.254163, 0.396552, 0.721236]])\n",
    "y_new = np.array([2.038740881834282])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 4\n",
    "x_new = np.array([[0.016750, 0.564445, 0.498901, 0.237872, 0.376071, 0.754913]])\n",
    "y_new = np.array([1.4161998340106972])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 5\n",
    "x_new = np.array([[0.202820, 0.354640, 0.005570, 0.266428, 0.373516, 0.013214]])\n",
    "y_new = np.array([0.12749585379582876])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 6\n",
    "x_new = np.array([[0.236909, 0.285530, 0.225819, 0.209358, 0.366238, 0.732886]])\n",
    "y_new = np.array([2.328267059938682])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 7\n",
    "x_new = np.array([[0.214572, 0.419397, 0.065811, 0.152936, 0.357296, 0.694855]])\n",
    "y_new = np.array([1.5873114037650422])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 8\n",
    "x_new = np.array([[0.296970, 0.175224, 0.967097, 0.217682,\n",
    "                   0.381161, 0.806737]])\n",
    "y_new = np.array([1.3151078392754891])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 9\n",
    "x_new = np.array([[0.311930, 0.244347, 0.263703, 0.233867,\n",
    "                   0.377674, 0.741498]])\n",
    "y_new = np.array([2.4596082089588753])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 10\n",
    "x_new = np.array([[0.346764, 0.117855, 0.122187, 0.232967,\n",
    "                   0.342263, 0.711485]])\n",
    "y_new = np.array([2.4637793179638843])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 11\n",
    "x_new = np.array([[0.272196, 0.506051, 0.223097, 0.236510, 0.326314, 0.797848]])\n",
    "y_new = np.array([1.578280104961618])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 12\n",
    "x_new = np.array([[0.274485, 0.070371, 0.163388, 0.213310, 0.371978, 0.732172]])\n",
    "y_new = np.array([2.356137319568785])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# week 13\n",
    "x_new = np.array([[0.345007, 0.158281, 0.249855, 0.159331, 0.319883, 0.696840]])\n",
    "y_new = np.array([2.4456844125131663])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "# final submission\n",
    "x_new = np.array([[0.321126, 0.159640, 0.384855, 0.209467, 0.349849, 0.720931]])\n",
    "y_new = np.array([2.8116569452461184])\n",
    "\n",
    "X = np.vstack((X, x_new))\n",
    "y = np.concatenate((y, y_new))\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=6)\n",
    "print(\"X:\\n\", X)\n",
    "print()\n",
    "print(\"y:\\n\", y)\n",
    "print()\n",
    "print(\"n: \", len(y))\n",
    "print()\n",
    "idx_best = np.argmax(y)\n",
    "print(f\"current maximum:\\nn: {idx_best+1}\\ny: {y[idx_best]}\\nX: {X[idx_best]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1cd6b6-b0a3-4c8d-98a3-f153c79ec80d",
   "metadata": {},
   "source": [
    "## Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80651aa-77f8-4f5b-a91a-2bcfdcf16222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next point to query: 0.286768-0.053079-0.410542-0.093678-0.376177-0.661625\n"
     ]
    }
   ],
   "source": [
    "# GP setup\n",
    "kernel = (ConstantKernel(1.0, (1e-2, 1e2)) *\n",
    "          Matern(length_scale=np.ones(d), nu=1.5) +\n",
    "          WhiteKernel(noise_level=5e-3, noise_level_bounds=(1e-6, 1e-1)))\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              n_restarts_optimizer=8,\n",
    "                              normalize_y=True,\n",
    "                              random_state=42)\n",
    "gp.fit(X, y)\n",
    "\n",
    "# Sobol candidates in [0,1]^6\n",
    "sob = Sobol(d=d, scramble=True, seed=None)\n",
    "C = sob.random_base2(m=18) \n",
    "\n",
    "# GP predictions\n",
    "mu, sigma = gp.predict(C, return_std=True)\n",
    "\n",
    "# Expected Improvement (EI)\n",
    "y_best = np.max(y)\n",
    "xi = 0.01            \n",
    "imp = mu - y_best - xi\n",
    "Z = imp / sigma\n",
    "ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "\n",
    "# 6) Pick next query (already in [0,1]^6)\n",
    "x_next = C[np.argmax(ei)]\n",
    "print(\"Next point to query:\",\n",
    "      \"-\".join(f\"{x:.6f}\" for x in x_next))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
